---
title: "fields_pt_data"
output: pdf_document
date: "2025-06-16"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(sf)           
library(fields)          
library(pROC)           
library(dplyr)
library(LatticeKrig)
setwd("~/Desktop/MINES/COGCC-Risk-Analysis/IC_Scripts/2024-2025/sp_point_data")
source("logisticSmoother.R")       
source("latkrig_logisticSmoother.R")
```

```{r}
flowlines <- st_read("final_dataset.geojson")
drop.cols <- c("unique_id","operator_number","flowline_id","location_id",
               "construct_date","spill_date","root_cause")
flowlines <- flowlines[, setdiff(names(flowlines), drop.cols)]
```

```{r}
df <- st_drop_geometry(flowlines)

na_rows <- df[!complete.cases(df), ]

risk_0 <- sum(na_rows$risk == 0, na.rm = TRUE)
risk_1 <- sum(na_rows$risk == 1, na.rm = TRUE)

cat("Rows with NAs and risk == 0:", risk_0, "\n")
cat("Rows with NAs and risk == 1:", risk_1, "\n")

df <- df[complete.cases(df), ]
```

```{r}
to.factor <- c("status","flowline_action","location_type","fluid","material")
df <- df %>% mutate(across(all_of(to.factor), as.factor))
```


```{r}
coord_mat <- do.call(rbind, strsplit(gsub("[()]", "", df$coords), ","))
coord_mat <- apply(coord_mat, 2, as.numeric)
colnames(coord_mat) <- c("lon", "lat")
```


```{r}
# Check for duplicates using R's default logic (based on numerical precision)
coord_rounded <- round(coord_mat, 6)

dupe_rows <- duplicated(as.data.frame(coord_rounded))
cat("R-level duplicates (rounded):", sum(dupe_rows), "\n")
```

```{r}
# mKrig checks for duplicate locations by converting each row into a string. Tiny differences vanish after string conversion, leading to dups. 

coord_strings <- cat.matrix(coord_mat)
dups_mkrig <- duplicated(coord_strings)
cat("mKrig-level duplicates:", sum(dups_mkrig), "\n")  # This shows duplicates, even if R's check didn't
```

```{r}
risk_dups <- df$risk[dups_mkrig]
table(risk_dups)
```

```{r}
# Drop mKrig-level duplicates and keep one copy per location, since only 2 duplicates are of risk = 1 
coord_clean <- coord_mat[!dups_mkrig, ]
y_clean <- df$risk[!dups_mkrig]
table(y_clean)
```


```{r}
nonzero_idx <- y_clean > 0
bubblePlot(coord_clean, y_clean,
           main = "Bubble Plot of Spill Risk",
           xlab = "Longitude", ylab = "Latitude")
```


```{r}
yTest <- ifelse(y_clean == 0, 0, 1)

# Get locations where a spill occurred
ind <- yTest == 1

plot(coord_clean[ind, ],
     main = "Spill Locations",
     xlab = "Longitude", ylab = "Latitude",
     pch = 16, col = "red", cex = 0.6)
```


```{r}
# compute medians
lon <- coord_clean[,1]
lat <- coord_clean[,2]
lon_mid <- median(lon)
lat_mid <- median(lat)

# build quadrant indices
quad1 <- which(lon >  lon_mid & lat >  lat_mid)  # NE
quad2 <- which(lon <= lon_mid & lat >  lat_mid)  # NW
quad3 <- which(lon <= lon_mid & lat <= lat_mid)  # SW
quad4 <- which(lon >  lon_mid & lat <= lat_mid)  # SE

quads <- list(
  NE = quad1,
  NW = quad2,
  SW = quad3,
  SE = quad4
)

# build a little summary table
quad_summary <- data.frame(
  quadrant = names(quads),
  total    = sapply(quads, length),
  risk0    = sapply(quads, function(i) sum(y_clean[i] == 0, na.rm=TRUE)),
  risk1    = sapply(quads, function(i) sum(y_clean[i] == 1, na.rm=TRUE))
)

print(quad_summary)
```


```{r}
# assume coord_clean, y_clean and logisticSmoother() are already in your workspace

# (re-)compute your four quadrants
lon     <- c2oord_clean[,1]
lat     <- coord_clean[,2]
lon_mid <- median(lon)
lat_mid <- median(lat)

quads <- list(
  NE = which(lon >  lon_mid & lat >  lat_mid),
  NW = which(lon <= lon_mid & lat >  lat_mid),
  SW = which(lon <= lon_mid & lat <= lat_mid),
  SE = which(lon >  lon_mid & lat <= lat_mid)
)

# fit one smoother per quadrant, timing each
models_quad <- list()
for(q in names(quads)) {
  idx <- quads[[q]]
  cat("------\n")
  cat("Fitting", q, "quadrant with", length(idx), "points…\n")
  
  t0 <- Sys.time()
  models_quad[[q]] <- logisticSmoother(
    s      = coord_clean[idx, ],
    y      = y_clean[idx],
    lambda = 1e-1
  )
  t1 <- Sys.time()
  
  elapsed <- round(as.numeric(difftime(t1, t0, units = "secs")), 2)
  cat(q, "finished in", elapsed, "seconds\n\n")
}

# inspect your fits
str(models_quad)
```


```{r}
library(fields)        # for predictSurface() & imagePlot()
library(viridis)       # if you want turbo()

# 1) Predict on a regular grid
gNE <- predictSurface(models_quad$NE, nx=80, ny=80)

# 2) Plot the estimated probability surface
imagePlot(
  gNE$x, gNE$y, 
  plogis(gNE$z),                # convert logit→prob
  col   = turbo(256),          # same palette you used before
  main  = "NE Quadrant Risk"
)

# 3) Overlay the positive cases
pts_NE <- coord_clean[ quads$NE, ]
y_NE   <- y_clean[ quads$NE ]

points(
  pts_NE[y_NE == 1, ],         # only the spill‐points
  col = "white", 
  pch = "."
)

# 4) add state boundaries (if you’d like)
US(add = TRUE, col = "magenta")
```







```{r}
# Run the spatial logistic smoother
look2 <- latkrig_logisticSmoother(coord_clean, y_clean, lambda = 1e-1)

# Predict on a regular gridw
gHat2 <- predictSurface(look2, nx = 80, ny = 80)

# Convert log-odds to probability
prob_surface <- exp(gHat2$z) / (1 + exp(gHat2$z))

imagePlot(gHat2$x, gHat2$y, prob_surface,
          col = turbo(256),
          main = "Smoothed Spill Risk Surface",
          xlab = "Longitude", ylab = "Latitude")
points(coord_clean[y_clean == 1, ], col = "white", pch = ".")
US(add = TRUE, col = "magenta")
```






















